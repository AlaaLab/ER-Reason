{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7e4795",
   "metadata": {},
   "source": [
    "# Acuity Classification Comparison: GPT-3.5 vs GPT-4o\n",
    "This notebook runs the acuity classification task using both GPT-3.5 and GPT-4o, allowing side-by-side comparison of model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Load and inspect dataset\n",
    "df = pd.read_csv('results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template based on original notebooks\n",
    "def format_prompt(row):\n",
    "    prompt = \"Predict the emergency department acuity level for this patient.\\n\\n\"\n",
    "    if 'primarychiefcomplaintname' in row:\n",
    "        prompt += f\"Chief Complaint: {row['primarychiefcomplaintname']}\\n\"\n",
    "    if 'age' in row:\n",
    "        prompt += f\"Age: {row['age']}\\n\"\n",
    "    if 'sex' in row:\n",
    "        prompt += f\"Sex: {row['sex']}\\n\"\n",
    "    if 'firstrace' in row:\n",
    "        prompt += f\"Race: {row['firstrace']}\\n\"\n",
    "    if 'Vital_Signs' in row:\n",
    "        prompt += f\"Vital Signs: {row['Vital_Signs']}\\n\"\n",
    "    prompt += \"\\nSelect the most appropriate acuity level from the following options ONLY:\\n\"\n",
    "    prompt += \"'Immediate', 'Emergent', 'Urgent', 'Less Urgent', 'Non-Urgent'\\n\\n\"\n",
    "    prompt += \"Respond with ONLY ONE of these five options.\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8635f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the OpenAI API\n",
    "def get_model_response(prompt, model_name='gpt-3.5-turbo'):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.1\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37c5455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions for both models\n",
    "results = []\n",
    "for i, row in df.iterrows():\n",
    "    prompt = format_prompt(row)\n",
    "    out_35 = get_model_response(prompt, 'gpt-3.5-turbo')\n",
    "    time.sleep(1)\n",
    "    out_4o = get_model_response(prompt, 'gpt-4o')\n",
    "    results.append({\n",
    "        'index': i,\n",
    "        'prompt': prompt,\n",
    "        'gpt-3.5-turbo': out_35,\n",
    "        'gpt-4o': out_4o,\n",
    "        'gold': row.get('acuitylevel', None)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13420cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame and display\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('acuity_comparison_results.csv', index=False)\n",
    "results_df[['gpt-3.5-turbo', 'gpt-4o', 'gold']].head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
