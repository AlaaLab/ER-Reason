{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ffae6ac",
   "metadata": {},
   "source": [
    "# O3-Mini Acuity Prediction \n",
    "This notebook predicts ER acuity level using the O3-Mini model, with all demographic inputs included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1304ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Imports and Setup\n",
    "import pandas as pd\n",
    "import time, os, requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('acuity_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4497469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîê Azure API Configuration\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "API_VERSION = '2024-12-01-preview'\n",
    "RESOURCE_ENDPOINT = os.getenv('RESOURCE_ENDPOINT')\n",
    "DEPLOYMENT_NAME = 'o3-mini-2025-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Prompt Generator Function \n",
    "def format_prompt(row):\n",
    "    prompt = \"Predict the emergency department acuity level for this patient.\\n\\n\"\n",
    "    if 'primarychiefcomplaintname' in row:\n",
    "        prompt += f\"Chief Complaint: {row['primarychiefcomplaintname']}\\n\"\n",
    "    if 'age' in row:\n",
    "        prompt += f\"Age: {row['age']}\\n\"\n",
    "    if 'sex' in row:\n",
    "        prompt += f\"Sex: {row['sex']}\\n\"\n",
    "    if 'firstrace' in row:\n",
    "        prompt += f\"Race: {row['firstrace']}\\n\"\n",
    "    if 'Vital_Signs' in row:\n",
    "        prompt += f\"Vital Signs: {row['Vital_Signs']}\\n\"\n",
    "    prompt += \"\\nSelect the most appropriate acuity level from the following options ONLY:\\n\"\n",
    "    prompt += \"'Immediate', 'Emergent', 'Urgent', 'Less Urgent', 'Non-Urgent'\\n\\n\"\n",
    "    prompt += \"Respond with ONLY ONE of these five options.\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dabda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ Query O3-Mini Model\n",
    "def call_o3(prompt):\n",
    "    url = f\"{RESOURCE_ENDPOINT}/openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version={API_VERSION}\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'api-key': API_KEY\n",
    "    }\n",
    "    payload = {\n",
    "        'messages': [\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "        ],\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['choices'][0]['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e77f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Run Prediction\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    prompt = format_prompt(row)\n",
    "    prediction = call_o3(prompt)\n",
    "    results.append(prediction)\n",
    "    time.sleep(1)  # Be nice to the API\n",
    "\n",
    "df['o3_prediction'] = results\n",
    "df.to_csv('o3_acuity_single_experiment.csv', index=False)\n",
    "df[['primarychiefcomplaintname', 'o3_prediction']].head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
