{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### disposition experiment code for gpt series: 4o and 3.5 on ER-Reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as ps\n",
    "import re\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import time\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results.csv') ## er-reason csv file here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_until_medical_decision(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    # Split at first occurrence of \"Medical Decision\" (case-insensitive)\n",
    "    parts = re.split(r'\\bMedical Decision\\b', text, flags=re.IGNORECASE)\n",
    "    return parts[0].strip() if parts else None\n",
    "\n",
    "df['ED_Presentations'] = df['ED_Provider_Notes_Text'].apply(extract_until_medical_decision) # This is part of the ED Provider Note that is the H&P. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # Display all rows\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.max_colwidth', None)  # Set max column width to None\n",
    "pd.set_option('display.width', None)  # Set width to None\n",
    "# First, let's test by hard coding your Mulesoft Azure API key into the next line\n",
    "API_KEY = 'x'  ##### Paste your API key between the quotes #####\n",
    "API_VERSION = '2024-06-01'  # For the most recent production release: https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation#latest-ga-api-release\n",
    "RESOURCE_ENDPOINT = 'x'  # no trailing slash--this is used by libraries as a partial URL\n",
    "DEPLOYMENT_NAME = \"gpt-35-turbo-16k\"  ## change to 4o deployment name as needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_disposition_with_dynamic_notes(row):\n",
    "    # Extract all available fields\n",
    "    chief_complaint = row['primarychiefcomplaintname']\n",
    "    sex = row['sex']\n",
    "    age = row['Age']\n",
    "    presentation = row['ED_Presentations']\n",
    "    \n",
    "    # Check if necessary basic fields exist\n",
    "    if pd.isna(chief_complaint):\n",
    "        return None, None  # Skip if chief complaint is missing, return None for both prediction and requested notes\n",
    "    \n",
    "    # Initialize available note types with their existence status\n",
    "    available_notes = {\n",
    "        'Discharge Summary': not pd.isna(row.get('Discharge_Summary_Text')),\n",
    "        'Progress Notes': not pd.isna(row.get('Progress_Note_Text')),\n",
    "        'H&P': not pd.isna(row.get('HP_Note_Text')),\n",
    "        'Echo': not pd.isna(row.get('Echo_Text')),\n",
    "        'Imaging': not pd.isna(row.get('Imaging_Text')),\n",
    "        'Consult': not pd.isna(row.get('Consult_Text')),\n",
    "        'ECG': not pd.isna(row.get('ECG_Text')),\n",
    "    }\n",
    "    \n",
    "    # Step 1: Ask the model which notes it wants to see (always include Discharge Summary if available)\n",
    "    url = f\"{RESOURCE_ENDPOINT}/openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version={API_VERSION}\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": API_KEY\n",
    "    }\n",
    "    \n",
    "    # First message to decide which notes to read\n",
    "    selection_payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an experienced Emergency Department (ED) physician. Your task is to decide which medical notes you need to read to predict the patient's ED disposition based on the chief complaint, PMH, physical exam findings, age, and sex.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Patient basic info: {age}yo {sex} with chief complaint: {chief_complaint}\\n\\n\"\n",
    "                                      f\"Available notes (respond ONLY with the names of notes you want to see, separated by commas):\\n\"\n",
    "                                      f\"- Discharge Summary: {'Available' if available_notes['Discharge Summary'] else 'Not available'}\\n\"\n",
    "                                      f\"- Progress Notes: {'Available' if available_notes['Progress Notes'] else 'Not available'}\\n\"\n",
    "                                      f\"- H&P: {'Available' if available_notes['H&P'] else 'Not available'}\\n\"\n",
    "                                      f\"- Echo: {'Available' if available_notes['Echo'] else 'Not available'}\\n\"\n",
    "                                      f\"- Imaging: {'Available' if available_notes['Imaging'] else 'Not available'}\\n\"\n",
    "                                      f\"- Consult: {'Available' if available_notes['Consult'] else 'Not available'}\\n\"\n",
    "                                      f\"- ECG: {'Available' if available_notes['ECG'] else 'Not available'}\\n\"\n",
    "                                      f\"Based on the chief complaint, list ONLY the note types you need to review (comma-separated, no explanation). Always include Discharge Summary if available:\"}\n",
    "        ],\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "    \n",
    "    # Request note selection with improved rate limit handling\n",
    "    retries = 0\n",
    "    requested_notes = []\n",
    "    notes_requested_str = \"\"  # String to track requested notes\n",
    "    max_retries = 5  # Increased retry attempts\n",
    "    \n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            # Exponential backoff with jitter for rate limiting\n",
    "            if retries > 0:\n",
    "                # Calculate delay with exponential backoff and random jitter\n",
    "                delay = (2 ** retries) + (random.random() * 2)\n",
    "                print(f\"Selection request: Backing off for {delay:.2f} seconds before retry {retries+1}/{max_retries}...\")\n",
    "                time.sleep(delay)\n",
    "            \n",
    "            selection_response = requests.post(url, headers=headers, json=selection_payload)\n",
    "            \n",
    "            # Handle rate limiting specifically\n",
    "            if selection_response.status_code == 429:  # Too Many Requests\n",
    "                retry_after = int(selection_response.headers.get('Retry-After', 60))\n",
    "                print(f\"Rate limited. Waiting {retry_after} seconds as instructed by API...\")\n",
    "                time.sleep(retry_after)\n",
    "                retries += 1\n",
    "                continue\n",
    "                \n",
    "            selection_response.raise_for_status()\n",
    "            \n",
    "            # Get requested note types\n",
    "            notes_text = selection_response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            requested_notes = [note.strip() for note in notes_text.split(',')]\n",
    "            \n",
    "            # Save the original request for the tracking column\n",
    "            notes_requested_str = notes_text\n",
    "            \n",
    "            # Filter out unavailable notes\n",
    "            requested_notes = [note for note in requested_notes \n",
    "                              if note in available_notes.keys() and available_notes[note]]\n",
    "            \n",
    "            # Always include Discharge Summary if available and not already requested\n",
    "            if available_notes['Discharge Summary'] and 'Discharge Summary' not in requested_notes:\n",
    "                requested_notes.append('Discharge Summary')\n",
    "                if notes_requested_str:\n",
    "                    notes_requested_str += \", Discharge Summary (auto-added)\"\n",
    "                else:\n",
    "                    notes_requested_str = \"Discharge Summary (auto-added)\"\n",
    "            \n",
    "            break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Note selection request failed: {e}. Retrying {retries+1}/{max_retries}...\")\n",
    "            retries += 1\n",
    "    \n",
    "    if not requested_notes and available_notes['Discharge Summary']:\n",
    "        # Default to discharge summary if selection failed but it's available\n",
    "        requested_notes = ['Discharge Summary']\n",
    "        notes_requested_str = \"Failed to get selections. Defaulted to: Discharge Summary\"\n",
    "    elif not requested_notes:\n",
    "        # If selection failed and no discharge summary, use whatever is available\n",
    "        available_notes_list = [note for note, available in available_notes.items() if available][:2]\n",
    "        requested_notes = available_notes_list\n",
    "        notes_requested_str = f\"Failed to get selections. Defaulted to: {', '.join(available_notes_list)}\"\n",
    "    \n",
    "    # Step 2: Prepare the actual notes content\n",
    "    notes_content = \"\"\n",
    "    \n",
    "    # Map note types to DataFrame column names\n",
    "    note_type_to_column = {\n",
    "        'Discharge Summary': 'Discharge_Summary_Text',\n",
    "        'Progress Notes': 'Progress_Note_Text',\n",
    "        'H&P': 'HP_Note_Text',\n",
    "        'Echo': 'Echo_Text',\n",
    "        'Imaging': 'Imaging_Text',\n",
    "        'Consult': 'Consult_Text',\n",
    "        'ECG': 'ECG_Text',\n",
    "    }\n",
    "    \n",
    "    # Function to truncate text to manage token limits\n",
    "    def truncate_text(text, max_chars=4000): # not used, for running purposes \n",
    "        if text and len(text) > max_chars:\n",
    "            return text[:max_chars] + \"...\"\n",
    "        return text\n",
    "    \n",
    "    # Add requested notes to content, with truncation\n",
    "    for note_type in requested_notes:\n",
    "        column_name = note_type_to_column.get(note_type)\n",
    "        if column_name and not pd.isna(row.get(column_name)):\n",
    "            notes_content += f\"\\n\\n{note_type}:\\n{truncate_text(row[column_name])}\"\n",
    "    \n",
    "    # Step 3: Generate the disposition prediction\n",
    "    prediction_payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an experienced Emergency Department (ED) physician tasked with predicting the most likely disposition for a patient based on their presentation and physicial, chief complaint, and available past medical information.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Based on the patient's chief complaint, age, sex, and available clinical information, predict the most likely ED disposition from the following choices: 'Discharge', 'Admit', 'Eloped', 'Transfer to Another Facility', 'AMA', 'OR Admit', 'LWBS after Triage', 'Send to L&D', 'Expired','Dismissed - Never Arrived', 'Observation', 'None'-- ONLY RESPOND WITH THESE OPTIONS, no explanations.\\n\\n\"\n",
    "                                      f\"Chief Complaint: {chief_complaint}\\n\"\n",
    "                                      f\"Age: {age}\\n\"\n",
    "                                      f\"Sex: {sex}\\n\"\n",
    "                                      f\"Current ED Presentation: {presentation}\\n\"\n",
    "                                      f\"{notes_content}\"}\n",
    "        ],\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    \n",
    "    # Request the disposition prediction with improved rate limit handling\n",
    "    retries = 0\n",
    "    max_retries = 5  # Increased retry attempts\n",
    "    \n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            # Exponential backoff with jitter for rate limiting\n",
    "            if retries > 0:\n",
    "                # Calculate delay with exponential backoff and random jitter\n",
    "                delay = (2 ** retries) + (random.random() * 2)\n",
    "                print(f\"Prediction request: Backing off for {delay:.2f} seconds before retry {retries+1}/{max_retries}...\")\n",
    "                time.sleep(delay)\n",
    "            \n",
    "            prediction_response = requests.post(url, headers=headers, json=prediction_payload)\n",
    "            \n",
    "            # Handle rate limiting specifically\n",
    "            if prediction_response.status_code == 429:  # Too Many Requests\n",
    "                retry_after = int(prediction_response.headers.get('Retry-After', 60))\n",
    "                print(f\"Rate limited. Waiting {retry_after} seconds as instructed by API...\")\n",
    "                time.sleep(retry_after)\n",
    "                retries += 1\n",
    "                continue\n",
    "                \n",
    "            prediction_response.raise_for_status()\n",
    "            return prediction_response.json()[\"choices\"][0][\"message\"][\"content\"].strip(), notes_requested_str\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Prediction request failed: {e}. Retrying {retries+1}/{max_retries}...\")\n",
    "            retries += 1\n",
    "    \n",
    "    return None, notes_requested_str  # Return None for prediction and the requested notes string if all retries fail\n",
    "\n",
    "# Import required additional libraries\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Process in batches with rate limit handling\n",
    "def process_in_batches(df, batch_size=10, pause_between_batches=30):\n",
    "    all_predictions = []\n",
    "    all_requested_notes = []\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    # Create backup file path with timestamp\n",
    "    import datetime\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    backup_path = f\"ed_disposition_backup_{timestamp}.csv\"\n",
    "    \n",
    "    for i in range(0, total_rows, batch_size):\n",
    "        print(f\"Processing batch {i//batch_size + 1} of {(total_rows-1)//batch_size + 1}...\")\n",
    "        \n",
    "        # Process one batch\n",
    "        end_idx = min(i + batch_size, total_rows)\n",
    "        batch_df = df.iloc[i:end_idx]\n",
    "        \n",
    "        # Apply function to batch and collect results\n",
    "        batch_results = batch_df.apply(lambda row: predict_disposition_with_dynamic_notes(row), axis=1)\n",
    "        \n",
    "        # Unpack results into separate lists\n",
    "        batch_predictions = [result[0] for result in batch_results]\n",
    "        batch_requested_notes = [result[1] for result in batch_results]\n",
    "        \n",
    "        # Add to overall results\n",
    "        all_predictions.extend(batch_predictions)\n",
    "        all_requested_notes.extend(batch_requested_notes)\n",
    "        \n",
    "        # Save progress after each batch\n",
    "        temp_df = df.copy()\n",
    "        \n",
    "        # Create lists with proper length\n",
    "        full_predictions = all_predictions + [None] * (total_rows - len(all_predictions))\n",
    "        full_requested_notes = all_requested_notes + [None] * (total_rows - len(all_requested_notes))\n",
    "        \n",
    "        # Fill in results we have so far\n",
    "        temp_df[\"Predicted_Disposition\"] = full_predictions\n",
    "        temp_df[\"Requested_Notes\"] = full_requested_notes\n",
    "        \n",
    "        # Save backup\n",
    "        temp_df.to_csv(backup_path, index=False)\n",
    "        print(f\"Progress saved to {backup_path}\")\n",
    "        \n",
    "        # Pause between batches to avoid rate limits (unless it's the last batch)\n",
    "        if end_idx < total_rows:\n",
    "            print(f\"Pausing for {pause_between_batches} seconds to avoid rate limits...\")\n",
    "            time.sleep(pause_between_batches)\n",
    "    \n",
    "    # Return results as a list of tuples to match the expected format\n",
    "    return list(zip(all_predictions, all_requested_notes))\n",
    "\n",
    "# Apply batch processing instead of processing all rows at once\n",
    "results = process_in_batches(df, batch_size=5, pause_between_batches=60)\n",
    "\n",
    "# Split the results into two columns\n",
    "df[\"Predicted_Disposition\"] = [result[0] for result in results]\n",
    "df[\"Requested_Notes\"] = [result[1] for result in results]\n",
    "\n",
    "# Add column to track accuracy of prediction if we have the actual disposition column\n",
    "if \"eddisposition\" in df.columns:\n",
    "    df[\"Prediction_Correct\"] = df[\"Predicted_Disposition\"] == df[\"eddisposition\"]\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    accuracy = (df[\"Prediction_Correct\"].sum() / df[\"Prediction_Correct\"].count()) * 100\n",
    "    print(f\"Overall disposition prediction accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Breakdown by disposition type\n",
    "    disposition_accuracy = df.groupby(\"eddisposition\").agg(\n",
    "        total_count=(\"eddisposition\", \"count\"),\n",
    "        correct_predictions=(\"Prediction_Correct\", \"sum\")\n",
    "    )\n",
    "    \n",
    "    # Calculate percentage accuracy for each disposition type\n",
    "    disposition_accuracy[\"accuracy_pct\"] = (\n",
    "        disposition_accuracy[\"correct_predictions\"] / \n",
    "        disposition_accuracy[\"total_count\"] * 100\n",
    "    )\n",
    "    \n",
    "    # Show top dispositions by count with accuracy\n",
    "    print(\"\\nDispositions by frequency with accuracy:\")\n",
    "    print(disposition_accuracy.sort_values(\"total_count\", ascending=False))\n",
    "\n",
    "# Save to CSV and Display\n",
    "df.to_csv(\"35_ed_dispo_predictions.csv\", index=False)\n",
    "print(\"Results saved to 35_ed_dispo_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall disposition prediction accuracy: 57.08%\n"
     ]
    }
   ],
   "source": [
    "# Add column to track accuracy of disposition prediction\n",
    "results[\"Prediction_Correct\"] = results[\"Predicted_Disposition\"] == results[\"eddisposition\"]\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = (results[\"Prediction_Correct\"].sum() / results[\"Prediction_Correct\"].count()) * 100\n",
    "print(f\"Overall disposition prediction accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
