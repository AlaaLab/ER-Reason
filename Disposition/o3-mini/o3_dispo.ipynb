{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## o-3 disposition prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)  # Display all rows\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.max_colwidth', None)  # Set max column width to None\n",
    "pd.set_option('display.width', None)  # Set width to None\n",
    "df = pd.read_csv('results.csv') ## this is the er-reason dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_until_medical_decision(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    # Split at first occurrence of \"Medical Decision\" (case-insensitive)\n",
    "    parts = re.split(r'\\bMedical Decision\\b', text, flags=re.IGNORECASE)\n",
    "    return parts[0].strip() if parts else None\n",
    "\n",
    "# Apply it to the column\n",
    "df['ED_Presentations'] = df['ED_Provider_Notes_Text'].apply(extract_until_medical_decision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import time\n",
    "import urllib.parse\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # Display all rows\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.max_colwidth', None)  # Set max column width to None\n",
    "pd.set_option('display.width', None)  # Set width to None\n",
    "# First, let's test by hard coding your Mulesoft Azure API key into the next line\n",
    "API_KEY = 'x='  ##### Paste your API key between the quotes #####\n",
    "API_VERSION = '2024-12-01-preview'  # For the most recent production release: https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation#latest-ga-api-release\n",
    "RESOURCE_ENDPOINT = 'x'  # no trailing slash--this is used by libraries as a partial URL\n",
    "DEPLOYMENT_NAME = \"o3-mini-2025-01-31\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.lib.azure.AzureOpenAI at 0x7ff07bc6a8d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=RESOURCE_ENDPOINT,\n",
    ")\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def debug_api_response(response, context=\"API Call\"):\n",
    "    \"\"\"Print detailed debugging info about API response\"\"\"\n",
    "    print(f\"--- DEBUG: {context} ---\")\n",
    "    print(f\"Status code: {response.status_code}\")\n",
    "    try:\n",
    "        json_data = response.json()\n",
    "        print(f\"JSON structure keys: {list(json_data.keys())}\")\n",
    "        if \"choices\" in json_data and len(json_data[\"choices\"]) > 0:\n",
    "            choice = json_data[\"choices\"][0]\n",
    "            print(f\"First choice keys: {list(choice.keys())}\")\n",
    "            if \"message\" in choice:\n",
    "                message = choice[\"message\"]\n",
    "                print(f\"Message keys: {list(message.keys())}\")\n",
    "                if \"content\" in message:\n",
    "                    print(f\"Content (first 100 chars): {message['content'][:100]}...\")\n",
    "                else:\n",
    "                    print(\"No 'content' in message\")\n",
    "            else:\n",
    "                print(\"No 'message' in first choice\")\n",
    "        else:\n",
    "            print(\"No 'choices' in response or empty choices\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing response: {e}\")\n",
    "        print(f\"Raw response text: {response.text[:500]}...\")\n",
    "    print(\"-------------------\")\n",
    "\n",
    "def predict_disposition_with_dynamic_notes(row):\n",
    "    # Extract all available fields\n",
    "    chief_complaint = row['primarychiefcomplaintname']\n",
    "    sex = row['sex']\n",
    "    age = row['Age']\n",
    "    presentation = row['ED_Presentations']\n",
    "    \n",
    "    # Check if necessary basic fields exist\n",
    "    if pd.isna(chief_complaint):\n",
    "        return None, None  # Skip if chief complaint is missing, return None for both prediction and requested notes\n",
    "    \n",
    "    # Initialize available note types with their existence status\n",
    "    available_notes = {\n",
    "        'Discharge Summary': not pd.isna(row.get('Discharge_Summary_Text')),\n",
    "        'Progress Notes': not pd.isna(row.get('Progress_Note_Text')),\n",
    "        'H&P': not pd.isna(row.get('HP_Note_Text')),\n",
    "        'Echo': not pd.isna(row.get('Echo_Text')),\n",
    "        'Imaging': not pd.isna(row.get('Imaging_Text')),\n",
    "        'Consult': not pd.isna(row.get('Consult_Text')),\n",
    "        'ECG': not pd.isna(row.get('ECG_Text')),\n",
    "    }\n",
    "    \n",
    "    # Step 1: Ask the model which notes it wants to see (always include Discharge Summary if available)\n",
    "    url = f\"{RESOURCE_ENDPOINT}/openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version={API_VERSION}\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": API_KEY\n",
    "    }\n",
    "    \n",
    "    # First message to decide which notes to read - using a straightforward format that works with o3\n",
    "    selection_payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": f\"You are an experienced Emergency Department (ED) physician. Your task is to decide which medical notes you need to read to predict the patient's ED disposition based on the chief complaint, PMH, physical exam findings, age, and sex. Patient basic info: {age}yo {sex} with chief complaint: {chief_complaint}\\n\\n\"\n",
    "                                      f\"Available notes (respond ONLY with the names of notes you want to see, separated by commas):\\n\"\n",
    "                                      f\"- Discharge Summary: {'Available' if available_notes['Discharge Summary'] else 'Not available'}\\n\"\n",
    "                                      f\"- Progress Notes: {'Available' if available_notes['Progress Notes'] else 'Not available'}\\n\"\n",
    "                                      f\"- H&P: {'Available' if available_notes['H&P'] else 'Not available'}\\n\"\n",
    "                                      f\"- Echo: {'Available' if available_notes['Echo'] else 'Not available'}\\n\"\n",
    "                                      f\"- Imaging: {'Available' if available_notes['Imaging'] else 'Not available'}\\n\"\n",
    "                                      f\"- Consult: {'Available' if available_notes['Consult'] else 'Not available'}\\n\"\n",
    "                                      f\"- ECG: {'Available' if available_notes['ECG'] else 'Not available'}\\n\"\n",
    "                                      f\"Based on the chief complaint, list ONLY the note types you need to review (comma-separated, no explanation). Always include Discharge Summary if available:\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Request note selection\n",
    "    retries = 0\n",
    "    requested_notes = []\n",
    "    notes_requested_str = \"\"\n",
    "    \n",
    "    while retries < 3:\n",
    "        try:\n",
    "            selection_response = requests.post(url, headers=headers, json=selection_payload)\n",
    "            selection_response.raise_for_status()\n",
    "            \n",
    "            # Debug the selection response\n",
    "            debug_api_response(selection_response, \"Note Selection\")\n",
    "            \n",
    "            # Get requested note types\n",
    "            response_json = selection_response.json()\n",
    "            if \"choices\" in response_json and len(response_json[\"choices\"]) > 0:\n",
    "                if \"message\" in response_json[\"choices\"][0]:\n",
    "                    notes_text = response_json[\"choices\"][0][\"message\"].get(\"content\", \"\").strip()\n",
    "                    requested_notes = [note.strip() for note in notes_text.split(',')]\n",
    "                    notes_requested_str = notes_text\n",
    "            \n",
    "            # Filter out unavailable notes\n",
    "            requested_notes = [note for note in requested_notes \n",
    "                               if note in available_notes.keys() and available_notes[note]]\n",
    "            \n",
    "            # Always include Discharge Summary if available and not already requested\n",
    "            if available_notes['Discharge Summary'] and 'Discharge Summary' not in requested_notes:\n",
    "                requested_notes.append('Discharge Summary')\n",
    "                if notes_requested_str:\n",
    "                    notes_requested_str += \", Discharge Summary (auto-added)\"\n",
    "                else:\n",
    "                    notes_requested_str = \"Discharge Summary (auto-added)\"\n",
    "            \n",
    "            break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Note selection request failed: {e}. Retrying {retries+1}/3...\")\n",
    "            time.sleep(5)\n",
    "            retries += 1\n",
    "    \n",
    "    # Default if selection failed\n",
    "    if not requested_notes and available_notes['Discharge Summary']:\n",
    "        requested_notes = ['Discharge Summary']\n",
    "        notes_requested_str = \"Failed to get selections. Defaulted to: Discharge Summary\"\n",
    "    elif not requested_notes:\n",
    "        available_notes_list = [note for note, available in available_notes.items() if available][:2]\n",
    "        requested_notes = available_notes_list\n",
    "        notes_requested_str = f\"Failed to get selections. Defaulted to: {', '.join(available_notes_list)}\"\n",
    "    \n",
    "    # Step 2: Prepare the actual notes content\n",
    "    notes_content = \"\"\n",
    "    note_type_to_column = {\n",
    "        'Discharge Summary': 'Discharge_Summary_Text',\n",
    "        'Progress Notes': 'Progress_Note_Text',\n",
    "        'H&P': 'HP_Note_Text',\n",
    "        'Echo': 'Echo_Text',\n",
    "        'Imaging': 'Imaging_Text',\n",
    "        'Consult': 'Consult_Text',\n",
    "        'ECG': 'ECG_Text',\n",
    "    }\n",
    "    \n",
    "    def truncate_text(text, max_chars=4000):\n",
    "        if text and len(text) > max_chars:\n",
    "            return text[:max_chars] + \"...\"\n",
    "        return text\n",
    "    \n",
    "    for note_type in requested_notes:\n",
    "        column_name = note_type_to_column.get(note_type)\n",
    "        if column_name and not pd.isna(row.get(column_name)):\n",
    "            notes_content += f\"\\n\\n{note_type}:\\n{truncate_text(row[column_name])}\"\n",
    "    \n",
    "    # Step 3: Generate the diagnosis prediction - using the exact same format as the working selection request\n",
    "    prediction_payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": f\"You are an experienced Emergency Department (ED) physician tasked with predicting the most likely disposition for a patient based on their presentation and physical, chief complaint, and available past medical information. Based on the patient's chief complaint, age, sex, and available clinical information, predict the most likely ED disposition from the following choices: 'Discharge', 'Admit', 'Eloped', 'Transfer to Another Facility', 'AMA', 'OR Admit', 'LWBS after Triage', 'Send to L&D', 'Expired','Dismissed - Never Arrived', 'Observation', 'None'-- ONLY RESPOND WITH THESE OPTIONS, no explanations.\\n\\n\"\n",
    "                                      f\"CURRENT Chief Complaint: {chief_complaint}\\n\"\n",
    "                                      f\"Age: {age}\\n\"\n",
    "                                      f\"Sex: {sex}\\n\"\n",
    "                                      f\"CURRENT ED Presentation: {presentation}\\n\"\n",
    "                                      f\"PAST MEDICAL HISTORY: {notes_content}\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Request the diagnosis prediction\n",
    "    retries = 0\n",
    "    while retries < 3:\n",
    "        try:\n",
    "            prediction_response = requests.post(url, headers=headers, json=prediction_payload)\n",
    "            prediction_response.raise_for_status()\n",
    "            \n",
    "            # Debug the prediction response\n",
    "            debug_api_response(prediction_response, \"Disposition Prediction\")\n",
    "            \n",
    "            # Extract the prediction from the response\n",
    "            response_json = prediction_response.json()\n",
    "            if \"choices\" in response_json and len(response_json[\"choices\"]) > 0:\n",
    "                if \"message\" in response_json[\"choices\"][0]:\n",
    "                    prediction = response_json[\"choices\"][0][\"message\"].get(\"content\", \"\").strip()\n",
    "                    return prediction, notes_requested_str\n",
    "            \n",
    "            # If we couldn't extract a prediction, return None\n",
    "            print(\"Warning: Could not extract prediction from API response\")\n",
    "            return None, notes_requested_str\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Prediction request failed: {e}. Retrying {retries+1}/3...\")\n",
    "            time.sleep(5)\n",
    "            retries += 1\n",
    "    \n",
    "    return None, notes_requested_str  # Return None for prediction and the requested notes string if all retries fail\n",
    "\n",
    "def process_in_batches(df, batch_size=20, output_file=\"o3_disposition_predictions.csv\"):\n",
    "    \"\"\"\n",
    "    Process dataframe in batches, saving progress after each batch\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to process\n",
    "        batch_size: Number of samples to process before saving\n",
    "        output_file: Where to save the results\n",
    "    \n",
    "    Returns:\n",
    "        Updated DataFrame with predictions\n",
    "    \"\"\"\n",
    "    # Check if output file exists to resume processing\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Found existing output file {output_file}, resuming from there...\")\n",
    "        existing_df = pd.read_csv(output_file)\n",
    "        \n",
    "        # Identify which rows have already been processed\n",
    "        processed_count = sum(~existing_df['Predicted_Disposition'].isna())\n",
    "        print(f\"Found {processed_count} already processed samples out of {len(existing_df)}\")\n",
    "        \n",
    "        # Merge existing predictions back to original dataframe\n",
    "        # Ensure index alignment for proper merging\n",
    "        if len(existing_df) == len(df) and 'Predicted_Disposition' in existing_df.columns:\n",
    "            # Create a mask for already processed rows\n",
    "            already_processed = ~existing_df['Predicted_Disposition'].isna()\n",
    "            \n",
    "            # Only keep valid predictions and requested notes\n",
    "            df.loc[already_processed, 'Predicted_Disposition'] = existing_df.loc[already_processed, 'Predicted_Disposition']\n",
    "            df.loc[already_processed, 'Requested_Notes'] = existing_df.loc[already_processed, 'Requested_Notes']\n",
    "            \n",
    "            print(f\"Restored {sum(already_processed)} existing predictions\")\n",
    "        else:\n",
    "            # If file exists but structure doesn't match, initialize columns\n",
    "            print(\"Output file structure doesn't match or is empty. Starting fresh.\")\n",
    "            df['Predicted_Disposition'] = None\n",
    "            df['Requested_Notes'] = None\n",
    "    else:\n",
    "        # Initialize prediction columns if starting fresh\n",
    "        print(\"Starting new prediction process...\")\n",
    "        df['Predicted_Disposition'] = None\n",
    "        df['Requested_Notes'] = None\n",
    "    \n",
    "    # Get indices of rows that still need processing\n",
    "    rows_to_process = df[pd.isna(df['Predicted_Disposition'])].index.tolist()\n",
    "    total_rows = len(rows_to_process)\n",
    "    \n",
    "    print(f\"Processing {total_rows} remaining samples in batches of {batch_size}\")\n",
    "    \n",
    "    # Process in batches\n",
    "    batch_count = 0\n",
    "    for i in range(0, total_rows, batch_size):\n",
    "        batch_indices = rows_to_process[i:i+batch_size]\n",
    "        batch_count += 1\n",
    "        \n",
    "        print(f\"Processing batch {batch_count}, samples {i+1}-{min(i+batch_size, total_rows)} of {total_rows}\")\n",
    "        \n",
    "        # Process each sample in the batch\n",
    "        for idx in batch_indices:\n",
    "            row = df.loc[idx]\n",
    "            \n",
    "            # Predict disposition\n",
    "            try:\n",
    "                prediction, notes_requested = predict_disposition_with_dynamic_notes(row)\n",
    "                \n",
    "                # Debug the results\n",
    "                print(f\"Sample {idx}: Prediction = '{prediction}', Notes = '{notes_requested[:30]}...'\")\n",
    "                \n",
    "                # Store results in dataframe\n",
    "                df.at[idx, 'Predicted_Disposition'] = prediction\n",
    "                df.at[idx, 'Requested_Notes'] = notes_requested\n",
    "                \n",
    "                # Print progress for every 5 samples\n",
    "                if (batch_indices.index(idx) + 1) % 5 == 0 or batch_indices.index(idx) + 1 == len(batch_indices):\n",
    "                    print(f\"  Processed {batch_indices.index(idx) + 1}/{len(batch_indices)} samples in current batch\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample {idx}: {e}\")\n",
    "                # Continue with next sample\n",
    "        \n",
    "        # Save after each batch\n",
    "        print(f\"Saving progress after batch {batch_count}...\")\n",
    "        df.to_csv(output_file, index=False)\n",
    "        \n",
    "        # Calculate completion percentage\n",
    "        completed = total_rows - len(rows_to_process[i+len(batch_indices):])\n",
    "        print(f\"Overall progress: {completed}/{total_rows} ({completed/total_rows*100:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data\n",
    "    print(\"Loading data...\")\n",
    "    # Replace with your actual data loading code\n",
    "    # df = pd.read_csv(\"your_data.csv\")\n",
    "    \n",
    "    # Set batch size and output file\n",
    "    BATCH_SIZE = 20\n",
    "    OUTPUT_FILE = \"new_o3_disposition_predictions.csv\"\n",
    "    \n",
    "    # Process data in batches with checkpoint saving\n",
    "    df = process_in_batches(df, batch_size=BATCH_SIZE, output_file=OUTPUT_FILE)\n",
    "    \n",
    "    print(f\"Processing complete! Results saved to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall disposition prediction accuracy: 63.08%\n"
     ]
    }
   ],
   "source": [
    "# Add column to track accuracy of disposition prediction\n",
    "results[\"Prediction_Correct\"] = results[\"Predicted_Disposition\"] == results[\"eddisposition\"]\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = (results[\"Prediction_Correct\"].sum() / results[\"Prediction_Correct\"].count()) * 100\n",
    "print(f\"Overall disposition prediction accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
